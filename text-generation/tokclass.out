
>> load dataset <<

** raw datasets
DatasetDict({
    train: Dataset({
        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],
        num_rows: 3453
    })
})

** raw/train/0
{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}

** raw/train/features/ner_tags
Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)


>> tokenize dataset <<

** # ex: 31

** ex
[('Germany', 5), ("'s", 0), ('representative', 0), ('to', 0), ('the', 0), ('European', 3), ('Union', 4), ("'s", 0), ('veterinary', 0), ('committee', 0), ('Werner', 1), ('Zwingmann', 2), ('said', 0), ('on', 0), ('Wednesday', 0), ('consumers', 0), ('should', 0), ('buy', 0), ('sheepmeat', 0), ('from', 0), ('countries', 0), ('other', 0), ('than', 0), ('Britain', 5), ('until', 0), ('the', 0), ('scientific', 0), ('advice', 0), ('was', 0), ('clearer', 0), ('.', 0)]

** # ex/subwords: 39

** ex/subwords
['[CLS]', 'germany', "'", 's', 'representative', 'to', 'the', 'european', 'union', "'", 's', 'veterinary', 'committee', 'werner', 'z', '##wing', '##mann', 'said', 'on', 'wednesday', 'consumers', 'should', 'buy', 'sheep', '##me', '##at', 'from', 'countries', 'other', 'than', 'britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.', '[SEP]']


>> align labels <<

** labels
[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]

** word_ids
[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, None]

** aligned_labels
[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]

** ex/subwords/aligned
[('[CLS]', -100), ('germany', 5), ("'", 0), ('s', 0), ('representative', 0), ('to', 0), ('the', 0), ('european', 3), ('union', 4), ("'", 0), ('s', 0), ('veterinary', 0), ('committee', 0), ('werner', 1), ('z', 2), ('##wing', 2), ('##mann', 2), ('said', 0), ('on', 0), ('wednesday', 0), ('consumers', 0), ('should', 0), ('buy', 0), ('sheep', 0), ('##me', 0), ('##at', 0), ('from', 0), ('countries', 0), ('other', 0), ('than', 0), ('britain', 5), ('until', 0), ('the', 0), ('scientific', 0), ('advice', 0), ('was', 0), ('clearer', 0), ('.', 0), ('[SEP]', -100)]

** tokenized
{'input_ids': [[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], [101, 2848, 13934, 102], [101, 9371, 2727, 1011, 5511, 1011, 2570, 102], [101, 1996, 2647, 3222, 2056, 2006, 9432, 2009, 18335, 2007, 2446, 6040, 2000, 10390, 2000, 18454, 2078, 2329, 12559, 2127, 6529, 5646, 3251, 5506, 11190, 4295, 2064, 2022, 11860, 2000, 8351, 1012, 102], [101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100], [-100, 1, 2, -100], [-100, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}

** tokenized datasets
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'chunk_tags', 'id', 'input_ids', 'labels', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['attention_mask', 'chunk_tags', 'id', 'input_ids', 'labels', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['attention_mask', 'chunk_tags', 'id', 'input_ids', 'labels', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})


>> load model <<


>> data collator <<


>> metric <<

** fake labels
[['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]

** fake preds
[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]

** example `('seqeval',)` metric calculation
{'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}, 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}, 'PER': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}, 'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 0.8064516129032258}


>> finetune <<

{'eval_loss': 0.1549311876296997, 'eval_precision': 0.764439166576703, 'eval_recall': 0.7921467725696386, 'eval_f1': 0.7780463685309306, 'eval_accuracy': 0.9567254992295106, 'eval_runtime': 3.1467, 'eval_samples_per_second': 1032.826, 'eval_steps_per_second': 8.263, 'epoch': 1.0}
{'eval_loss': 0.08630432933568954, 'eval_precision': 0.8692633177823587, 'eval_recall': 0.896297124958049, 'eval_f1': 0.8825732540207095, 'eval_accuracy': 0.9754078828220567, 'eval_runtime': 3.2129, 'eval_samples_per_second': 1011.56, 'eval_steps_per_second': 8.092, 'epoch': 2.0}
{'eval_loss': 0.07179789245128632, 'eval_precision': 0.895468476357268, 'eval_recall': 0.9152030428459559, 'eval_f1': 0.9052282157676348, 'eval_accuracy': 0.9790458639808093, 'eval_runtime': 3.2271, 'eval_samples_per_second': 1007.112, 'eval_steps_per_second': 8.057, 'epoch': 3.0}
{'eval_loss': 0.06890600919723511, 'eval_precision': 0.9009933413382818, 'eval_recall': 0.9233695044188388, 'eval_f1': 0.9120441988950276, 'eval_accuracy': 0.9800149331977696, 'eval_runtime': 3.3543, 'eval_samples_per_second': 968.915, 'eval_steps_per_second': 7.751, 'epoch': 4.0}
{'loss': 0.1745, 'learning_rate': 1.8181818181818183e-06, 'epoch': 4.55}
{'eval_loss': 0.06735536456108093, 'eval_precision': 0.9059482001755926, 'eval_recall': 0.9234813737554536, 'eval_f1': 0.9146307683784832, 'eval_accuracy': 0.9806821611832176, 'eval_runtime': 3.2044, 'eval_samples_per_second': 1014.242, 'eval_steps_per_second': 8.114, 'epoch': 5.0}
{'train_runtime': 133.6134, 'train_samples_per_second': 525.434, 'train_steps_per_second': 4.116, 'train_loss': 0.16311179247769442, 'epoch': 5.0}

>> predict <<

** prediction results
{'LOC': {'precision': 0.9348473566641846, 'recall': 0.9591291061879297, 'f1': 0.9468325791855203, 'number': 2618}, 'MISC': {'precision': 0.7591582229150429, 'recall': 0.7912266450040617, 'f1': 0.7748607796340493, 'number': 1231}, 'ORG': {'precision': 0.8621673003802282, 'recall': 0.882295719844358, 'f1': 0.8721153846153846, 'number': 2056}, 'PER': {'precision': 0.9726883843369529, 'recall': 0.974291364535267, 'f1': 0.9734892145562325, 'number': 3034}, 'overall_precision': 0.9059482001755926, 'overall_recall': 0.9234813737554536, 'overall_f1': 0.9146307683784832, 'overall_accuracy': 0.9806821611832176}


>> eval <<

** RESULT
{'eval_loss': 0.06735536456108093, 'eval_precision': 0.9059482001755926, 'eval_recall': 0.9234813737554536, 'eval_f1': 0.9146307683784832, 'eval_accuracy': 0.9806821611832176, 'eval_runtime': 3.161, 'eval_samples_per_second': 1028.171, 'eval_steps_per_second': 8.225, 'epoch': 5.0}

